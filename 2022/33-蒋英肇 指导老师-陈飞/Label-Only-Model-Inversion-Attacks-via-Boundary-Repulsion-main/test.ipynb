{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attacking any 300 targets\n",
      "iter 0: current number of distinct labels 207\n",
      "iter 1: current number of distinct labels 300\n",
      " 1/300: attacking iden 246\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from brep_mi_utils import *\n",
    "from classify import *\n",
    "from generator import *\n",
    "from discri import *\n",
    "from utils import *\n",
    "from torch.nn import DataParallel\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import os, logging\n",
    "import numpy as np\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import yaml\n",
    "from brep_mi import attack, gen_points_on_sphere\n",
    "\n",
    "with open('config2.yaml') as config_file:\n",
    "    attack_params = yaml.safe_load(config_file)\n",
    "\n",
    "n_classes = 1000\n",
    "target_model = FaceNet64(n_classes)\n",
    "\n",
    "path_target_model = 'models/FaceNet64_88.50.tar'\n",
    "target_model = torch.nn.DataParallel(target_model).cuda()\n",
    "ckp_target_model = torch.load(path_target_model)\n",
    "target_model.load_state_dict(ckp_target_model['state_dict'], strict=False)\n",
    "\n",
    "path_G = 'models/GAN/celeba_G.tar'\n",
    "G = Generator(attack_params['z_dim'])\n",
    "G = torch.nn.DataParallel(G).cuda()\n",
    "ckp_G = torch.load(path_G)\n",
    "G.load_state_dict(ckp_G['state_dict'], strict=False)\n",
    "\n",
    "E = FaceNet(1000)\n",
    "E = torch.nn.DataParallel(E).cuda()\n",
    "path_E = 'models/FaceNet_95.88.tar'\n",
    "ckp_E = torch.load(path_E)\n",
    "E.load_state_dict(ckp_E['state_dict'], strict=False)\n",
    "\n",
    "attack_imgs_dir = 'decision/attack_imgs/'\n",
    "os.makedirs(attack_imgs_dir, exist_ok=True)\n",
    "\n",
    "target_model.eval()\n",
    "G.eval()\n",
    "E.eval()\n",
    "\n",
    "def attack(attack_params,\n",
    "           target_model,\n",
    "           evaluator_model,\n",
    "           generator_model,\n",
    "           attack_imgs_dir,\n",
    "           private_domain_imgs_path):\n",
    "    # attack the same targets using same initial points as saved experiment\n",
    "    if 'targets_from_exp' in attack_params:\n",
    "        print(\"loading intial points from experiment dir: {}\".format(attack_params['targets_from_exp']))\n",
    "        points = gen_initial_points_from_exp(attack_params['targets_from_exp'])\n",
    "\n",
    "    # attack same targets as experiment, but generate new random initial points\n",
    "    elif 'gen_idens_as_exp' in attack_params:\n",
    "        print(\"attacking same targets as experiment dir: {}\".format(attack_params['gen_idens_as_exp']))\n",
    "        points = gen_idens_as_exp(attack_params['gen_idens_as_exp'],\n",
    "                                  attack_params['batch_dim_for_initial_points'],\n",
    "                                  generator_model,\n",
    "                                  target_model,\n",
    "                                  attack_params['point_clamp_min'],\n",
    "                                  attack_params['point_clamp_max'],\n",
    "                                  attack_params['z_dim'])\n",
    "    # attack target classes from iden_range_min to iden_range_max\n",
    "    elif attack_params['targeted_attack']:\n",
    "        print(\"attacking the targets from: {} to {}\".format(attack_params['iden_range_min'],\n",
    "                                                            attack_params['iden_range_max']))\n",
    "        points = gen_initial_points_targeted(attack_params['batch_dim_for_initial_points'],\n",
    "                                             generator_model,\n",
    "                                             target_model,\n",
    "                                             attack_params['point_clamp_min'],\n",
    "                                             attack_params['point_clamp_max'],\n",
    "                                             attack_params['z_dim'],\n",
    "                                             attack_params['iden_range_min'],\n",
    "                                             attack_params['iden_range_max'])\n",
    "    # attack any N labels\n",
    "    else:\n",
    "        print(\"attacking any {} targets\".format(attack_params['num_targets']))\n",
    "        #poinns 是num_targets长度的字典，每个value都是100*1的tensor\n",
    "        #可以理解为初始的数量为num_target的圆心点\n",
    "        points = gen_initial_points_untargeted(attack_params['num_targets'],\n",
    "                                               attack_params['batch_dim_for_initial_points'],\n",
    "                                               generator_model,\n",
    "                                               target_model,\n",
    "                                               attack_params['point_clamp_min'],\n",
    "                                               attack_params['point_clamp_max'],\n",
    "                                               attack_params['z_dim'])\n",
    "\n",
    "    # points.cuda()\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    correct_on_eval = 0\n",
    "    current_iter = 0\n",
    "    #target_class在无目标的攻击中圆心点的初始类\n",
    "    for target_class in points:\n",
    "        current_iter += 1\n",
    "        #当前圆心点\n",
    "        current_point = points[target_class].cuda()\n",
    "        print(\" {}/{}: attacking iden {}\".format(current_iter, len(points), target_class))\n",
    "        target_class_tensor = torch.tensor([target_class]).cuda()\n",
    "\n",
    "        # save the first generated image, and current point (z) to the iden_dir\n",
    "        current_iden_dir = os.path.join(attack_imgs_dir, \"iden_{}\".format(target_class))\n",
    "        os.makedirs(current_iden_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "        first_img = generator_model(current_point.unsqueeze(0))\n",
    "        save_tensor_images(first_img[0].detach(),\n",
    "                           os.path.join(current_iden_dir, \"original_first_point.png\".format(current_iter)))\n",
    "        np.save(os.path.join(current_iden_dir, 'initial_z_point'),\n",
    "                current_point.cpu().detach().numpy())\n",
    "\n",
    "        # copy the groundtruth images of the target to the attack dir\n",
    "        # please put all groundtruth images in one single image called all.png\n",
    "        # the path to the groundtruth image of label should be  \"$dataset_dir/label/all.png\"\n",
    "        if len(private_domain_imgs_path) > 0:\n",
    "            shutil.copy(os.path.join(private_domain_imgs_path, str(target_class), 'all.png'),\n",
    "                        os.path.join(current_iden_dir, 'groundtruth_imgs.png'))\n",
    "\n",
    "        # first image should always be inside target class\n",
    "        assert is_target_class(first_img, target_class, target_model).item() == 1\n",
    "\n",
    "        _, initial_loss = decision(generator_model(current_point.unsqueeze(0)), target_model, score=True,\n",
    "                                   criterion=criterion, target=target_class_tensor)\n",
    "\n",
    "        correct_on_eval += attack_single_target(current_point, target_class, initial_loss, generator_model,\n",
    "                                                target_model, evaluator_model, attack_params, criterion,\n",
    "                                                current_iden_dir)\n",
    "        current_acc_on_eval = correct_on_eval / current_iter\n",
    "        print(\"current acc on eval model: {:.2f}%\".format(current_acc_on_eval * 100))\n",
    "\n",
    "    total_acc_on_eval = correct_on_eval / len(points)\n",
    "    print(\"total acc on eval model: {:.2f}%\".format(total_acc_on_eval * 100))\n",
    "\n",
    "\n",
    "attack(attack_params,\n",
    "       target_model,\n",
    "       E,\n",
    "       G,\n",
    "       attack_imgs_dir,\n",
    "       '')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attacking any 300 targets\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_mm)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 91>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     87\u001B[0m     total_acc_on_eval \u001B[38;5;241m=\u001B[39m correct_on_eval \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(points)\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal acc on eval model: \u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(total_acc_on_eval \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m))\n\u001B[1;32m---> 91\u001B[0m \u001B[43mattack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattack_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[43m       \u001B[49m\u001B[43mtarget_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[43m       \u001B[49m\u001B[43mE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[43m       \u001B[49m\u001B[43mG\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     95\u001B[0m \u001B[43m       \u001B[49m\u001B[43mattack_imgs_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[43m       \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36mattack\u001B[1;34m(attack_params, target_model, evaluator_model, generator_model, attack_imgs_dir, private_domain_imgs_path)\u001B[0m\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattacking any \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(attack_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_targets\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;66;03m#poinns 是num_targets长度的字典，每个value都是100*1的tensor\u001B[39;00m\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;66;03m#可以理解为初始的数量为num_target的圆心点\u001B[39;00m\n\u001B[1;32m---> 39\u001B[0m     points \u001B[38;5;241m=\u001B[39m \u001B[43mgen_initial_points_untargeted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattack_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnum_targets\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mattack_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbatch_dim_for_initial_points\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mgenerator_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mtarget_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mattack_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpoint_clamp_min\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mattack_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpoint_clamp_max\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mattack_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mz_dim\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# points.cuda()\u001B[39;00m\n\u001B[0;32m     48\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\u001B[38;5;241m.\u001B[39mcuda()\n",
      "File \u001B[1;32m~\\Desktop\\论文demo\\Label-Only-Model-Inversion-Attacks-via-Boundary-Repulsion-main\\brep_mi_utils.py:55\u001B[0m, in \u001B[0;36mgen_initial_points_untargeted\u001B[1;34m(num_idens, batch_size, G, model, min_clip, max_clip, z_dim)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     z \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(batch_size, z_dim)\u001B[38;5;241m.\u001B[39mcuda()\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mclamp(\u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m=\u001B[39mmin_clip, \u001B[38;5;28mmax\u001B[39m\u001B[38;5;241m=\u001B[39mmax_clip)\n\u001B[1;32m---> 55\u001B[0m     first_img \u001B[38;5;241m=\u001B[39m \u001B[43mG\u001B[49m\u001B[43m(\u001B[49m\u001B[43mz\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;66;03m# our target class is the now the current class of the generated image\u001B[39;00m\n\u001B[0;32m     57\u001B[0m     target_classes \u001B[38;5;241m=\u001B[39m decision(first_img, model)\n",
      "File \u001B[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Desktop\\论文demo\\Label-Only-Model-Inversion-Attacks-via-Boundary-Repulsion-main\\generator.py:26\u001B[0m, in \u001B[0;36mGenerator.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 26\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ml1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m     y \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mview(y\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m     28\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ml2_5(y)\n",
      "File \u001B[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 139\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_mm)"
     ]
    }
   ],
   "source": [
    "def attack(attack_params,\n",
    "           target_model,\n",
    "           evaluator_model,\n",
    "           generator_model,\n",
    "           attack_imgs_dir,\n",
    "           private_domain_imgs_path):\n",
    "    # attack the same targets using same initial points as saved experiment\n",
    "    if 'targets_from_exp' in attack_params:\n",
    "        print(\"loading intial points from experiment dir: {}\".format(attack_params['targets_from_exp']))\n",
    "        points = gen_initial_points_from_exp(attack_params['targets_from_exp'])\n",
    "\n",
    "    # attack same targets as experiment, but generate new random initial points\n",
    "    elif 'gen_idens_as_exp' in attack_params:\n",
    "        print(\"attacking same targets as experiment dir: {}\".format(attack_params['gen_idens_as_exp']))\n",
    "        points = gen_idens_as_exp(attack_params['gen_idens_as_exp'],\n",
    "                                  attack_params['batch_dim_for_initial_points'],\n",
    "                                  generator_model,\n",
    "                                  target_model,\n",
    "                                  attack_params['point_clamp_min'],\n",
    "                                  attack_params['point_clamp_max'],\n",
    "                                  attack_params['z_dim'])\n",
    "    # attack target classes from iden_range_min to iden_range_max\n",
    "    elif attack_params['targeted_attack']:\n",
    "        print(\"attacking the targets from: {} to {}\".format(attack_params['iden_range_min'],\n",
    "                                                            attack_params['iden_range_max']))\n",
    "        points = gen_initial_points_targeted(attack_params['batch_dim_for_initial_points'],\n",
    "                                             generator_model,\n",
    "                                             target_model,\n",
    "                                             attack_params['point_clamp_min'],\n",
    "                                             attack_params['point_clamp_max'],\n",
    "                                             attack_params['z_dim'],\n",
    "                                             attack_params['iden_range_min'],\n",
    "                                             attack_params['iden_range_max'])\n",
    "    # attack any N labels\n",
    "    else:\n",
    "        print(\"attacking any {} targets\".format(attack_params['num_targets']))\n",
    "        #poinns 是num_targets长度的字典，每个value都是100*1的tensor\n",
    "        #可以理解为初始的数量为num_target的圆心点\n",
    "        points = gen_initial_points_untargeted(attack_params['num_targets'],\n",
    "                                               attack_params['batch_dim_for_initial_points'],\n",
    "                                               generator_model,\n",
    "                                               target_model,\n",
    "                                               attack_params['point_clamp_min'],\n",
    "                                               attack_params['point_clamp_max'],\n",
    "                                               attack_params['z_dim'])\n",
    "\n",
    "    # points.cuda()\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    correct_on_eval = 0\n",
    "    current_iter = 0\n",
    "    #target_class在无目标的攻击中圆心点的初始类\n",
    "    for target_class in points:\n",
    "        current_iter += 1\n",
    "        #当前圆心点\n",
    "        current_point = points[target_class].cuda()\n",
    "        print(\" {}/{}: attacking iden {}\".format(current_iter, len(points), target_class))\n",
    "        target_class_tensor = torch.tensor([target_class]).cuda()\n",
    "\n",
    "        # save the first generated image, and current point (z) to the iden_dir\n",
    "        current_iden_dir = os.path.join(attack_imgs_dir, \"iden_{}\".format(target_class))\n",
    "        os.makedirs(current_iden_dir, exist_ok=True)\n",
    "        first_img = generator_model(current_point.unsqueeze(0))\n",
    "        save_tensor_images(first_img[0].detach(),\n",
    "                           os.path.join(current_iden_dir, \"original_first_point.png\".format(current_iter)))\n",
    "        np.save(os.path.join(current_iden_dir, 'initial_z_point'),\n",
    "                current_point.cpu().detach().numpy())\n",
    "\n",
    "        # copy the groundtruth images of the target to the attack dir\n",
    "        # please put all groundtruth images in one single image called all.png\n",
    "        # the path to the groundtruth image of label should be  \"$dataset_dir/label/all.png\"\n",
    "        if len(private_domain_imgs_path) > 0:\n",
    "            shutil.copy(os.path.join(private_domain_imgs_path, str(target_class), 'all.png'),\n",
    "                        os.path.join(current_iden_dir, 'groundtruth_imgs.png'))\n",
    "\n",
    "        # first image should always be inside target class\n",
    "        assert is_target_class(first_img, target_class, target_model).item() == 1\n",
    "\n",
    "        _, initial_loss = decision(generator_model(current_point.unsqueeze(0)), target_model, score=True,\n",
    "                                   criterion=criterion, target=target_class_tensor)\n",
    "\n",
    "        correct_on_eval += attack_single_target(current_point, target_class, initial_loss, generator_model,\n",
    "                                                target_model, evaluator_model, attack_params, criterion,\n",
    "                                                current_iden_dir)\n",
    "        current_acc_on_eval = correct_on_eval / current_iter\n",
    "        print(\"current acc on eval model: {:.2f}%\".format(current_acc_on_eval * 100))\n",
    "\n",
    "    total_acc_on_eval = correct_on_eval / len(points)\n",
    "    print(\"total acc on eval model: {:.2f}%\".format(total_acc_on_eval * 100))\n",
    "\n",
    "\n",
    "attack(attack_params,\n",
    "       target_model,\n",
    "       E,\n",
    "       G,\n",
    "       attack_imgs_dir,\n",
    "       '')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: current number of distinct labels 205\n",
      "iter 1: current number of distinct labels 300\n"
     ]
    }
   ],
   "source": [
    "def gen_initial_points_untargeted(num_idens, batch_size, G, model, min_clip, max_clip, z_dim):\n",
    "    # print('Generating initial points for attacked target classes: Untarg`eted Attack')\n",
    "    initial_points = {}  # {194:1}\n",
    "    max_idens_reached = False\n",
    "    current_iter = 0\n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            z = torch.randn(batch_size, z_dim).cuda().float().clamp(min=min_clip, max=max_clip)\n",
    "            first_img = G(z)\n",
    "            # our target class is the now the current class of the generated image\n",
    "            target_classes = decision(first_img, model)\n",
    "\n",
    "            for i in range(target_classes.shape[0]):\n",
    "                current_label = target_classes[i].item()\n",
    "                if current_label in initial_points:\n",
    "                    continue\n",
    "\n",
    "                initial_points[current_label] = z[i]\n",
    "\n",
    "                if len(initial_points) == num_idens:\n",
    "                    break\n",
    "            print(\"iter {}: current number of distinct labels {}\".format(current_iter, len(initial_points)))\n",
    "            current_iter += 1\n",
    "            if len(initial_points) == num_idens:\n",
    "                break\n",
    "    # initial_points.pop(194, None)\n",
    "    return initial_points\n",
    "\n",
    "\n",
    "points = gen_initial_points_untargeted(300,\n",
    "                                       256,\n",
    "                                       G,\n",
    "                                       target_model,\n",
    "                                       -1.5,\n",
    "                                       1.5,\n",
    "                                       100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'attack_params' from 'main' (C:\\Users\\蒋英肇\\Desktop\\论文demo\\Label-Only-Model-Inversion-Attacks-via-Boundary-Repulsion-main\\main.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmain\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m attack_params, attack_imgs_dir\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbrep_mi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m attack_single_target\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mshutil\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'attack_params' from 'main' (C:\\Users\\蒋英肇\\Desktop\\论文demo\\Label-Only-Model-Inversion-Attacks-via-Boundary-Repulsion-main\\main.py)"
     ]
    }
   ],
   "source": [
    "def attack_single_target(current_point, target_class, current_loss, G,\n",
    "                         target_model, evaluator_model, attack_params, criterion, current_iden_dir):\n",
    "    current_iter = 0\n",
    "    last_iter_when_radius_changed = 0\n",
    "    SGDM = 0\n",
    "\n",
    "    # create log file\n",
    "    #log_file = open(os.path.join(current_iden_dir, 'train_log'), 'w')\n",
    "    losses = []\n",
    "    target_class_tensor = torch.tensor([target_class]).cuda()\n",
    "    current_sphere_radius = attack_params['current_sphere_radius']\n",
    "\n",
    "    last_success_on_eval = False\n",
    "    # Outer loop handle all sphere radii\n",
    "    while current_iter - last_iter_when_radius_changed < attack_params['max_iters_at_radius_before_terminate']:\n",
    "\n",
    "        # inner loop handle one single sphere radius\n",
    "        while current_iter - last_iter_when_radius_changed < attack_params['max_iters_at_radius_before_terminate']:\n",
    "\n",
    "            #grad_accumulate = torch.zeros([100]).cuda()\n",
    "            new_radius = False\n",
    "\n",
    "            # step size is similar to learning rate\n",
    "            # we limit max step size to 3. But feel free to change it\n",
    "            step_size = min(current_sphere_radius / 3, 3)\n",
    "\n",
    "            # sample points on the sphere\n",
    "            # 32*100    32*100\n",
    "            new_points, perturbation_directions = gen_points_on_sphere(current_point,\n",
    "                                                                       attack_params['sphere_points_count'],\n",
    "                                                                       current_sphere_radius)\n",
    "\n",
    "            # get the predicted labels of the target model on the sphere points\n",
    "            # 32个 +1 or -1 的集合\n",
    "            # 等于论文中 sign(Mc(z))\n",
    "            # tensor(32)\n",
    "            new_points_classification = is_target_class(G(new_points), target_class, target_model)\n",
    "\n",
    "            # handle case where all(or some percentage) sphere points lie in decision boundary. We increment sphere size\n",
    "            if new_points_classification.sum() > 0.75 * attack_params[\n",
    "                'sphere_points_count']:  # == attack_params['sphere_points_count']:\n",
    "                '''save_tensor_images(G(current_point.unsqueeze(0))[0].detach(),\n",
    "                                   os.path.join(current_iden_dir,\n",
    "                                                \"last_img_of_radius_{:.4f}_iter_{}.png\".format(current_sphere_radius,\n",
    "                                                                                               current_iter)))'''\n",
    "                # update the current sphere radius\n",
    "                current_sphere_radius = current_sphere_radius * attack_params['sphere_expansion_coeff']\n",
    "\n",
    "                #log_file.write(\"new sphere radius at iter: {} \".format(current_iter))\n",
    "                new_radius = True\n",
    "                last_iter_when_radius_changed = current_iter\n",
    "\n",
    "            # get the update direction, which is the mean of all points outside boundary if 'repulsion_only' is used. Otherwise it is the mean of all points * their classification (1,-1)\n",
    "            if attack_params['repulsion_only'] == True:\n",
    "                #等于论文中的 Qc(z)\n",
    "                new_points_classification = (new_points_classification - 1) / 2\n",
    "            #tensor(100)\n",
    "            grad_direction = torch.mean(new_points_classification.unsqueeze(1) * perturbation_directions,\n",
    "                                        axis=0) / current_sphere_radius\n",
    "\n",
    "            #grad_accumulate = 0.9 * grad_accumulate + 0.1 * grad_direction\n",
    "\n",
    "            #grad_direction = grad_direction + grad_accumulate\n",
    "\n",
    "            # move the current point with stepsize towards grad_direction\n",
    "            #tensor(100)\n",
    "            current_point_new = current_point + step_size * grad_direction\n",
    "            current_point_new = current_point_new.clamp(min=attack_params['point_clamp_min'],\n",
    "                                                        max=attack_params['point_clamp_max'])\n",
    "            #tensor(1,3,64,64)\n",
    "            current_img = G(current_point_new.unsqueeze(0))\n",
    "            if is_target_class(current_img, target_class, target_model)[0] == -1:\n",
    "                #log_file.write(\"current point is outside target class boundary\")\n",
    "                break\n",
    "\n",
    "            current_point = current_point_new\n",
    "            _, current_loss = decision(current_img, target_model, score=True, criterion=criterion,\n",
    "                                       target=target_class_tensor)\n",
    "\n",
    "            '''if current_iter % 50 == 0 or (current_iter < 200 and current_iter % 20 == 0):\n",
    "                save_tensor_images(current_img[0].detach(),\n",
    "                                   os.path.join(current_iden_dir, \"iter{}.png\".format(current_iter)))'''\n",
    "\n",
    "            eval_decision = decision_Evaluator(current_img, evaluator_model)\n",
    "            correct_on_eval = True if eval_decision == target_class else False\n",
    "            if new_radius:\n",
    "                point_before_inc_radius = current_point.clone()\n",
    "                last_success_on_eval = correct_on_eval\n",
    "                break\n",
    "            '''iter_str = \"iter: {}, current_sphere_radius: {}, step_size: {:.2f} sum decisions: {}, loss: {:.4f}, eval predicted class {}, classified correct on Eval {}\".format(\n",
    "                current_iter, current_sphere_radius, step_size,\n",
    "                new_points_classification.sum(),\n",
    "                current_loss.item(),\n",
    "                eval_decision,\n",
    "                correct_on_eval)'''\n",
    "\n",
    "            #log_file.write(iter_str + '\\n')\n",
    "            losses.append(current_loss.item())\n",
    "            current_iter += 1\n",
    "\n",
    "    #log_file.close()\\\n",
    "\n",
    "    # acc = 1 if decision_Evaluator(G(current_point.unsqueeze(0)),evaluator_model)==target_class  else 0\n",
    "    acc = 1 if last_success_on_eval is True else 0\n",
    "    return acc\n",
    "\n",
    "\n",
    "points = gen_initial_points_untargeted(attack_params['num_targets'],\n",
    "                                       attack_params['batch_dim_for_initial_points'],\n",
    "                                       G,\n",
    "                                       target_model,\n",
    "                                       attack_params['point_clamp_min'],\n",
    "                                       attack_params['point_clamp_max'],\n",
    "                                       attack_params['z_dim'])\n",
    "for target_class in points:\n",
    "    current_point = points[target_class].cuda()\n",
    "    target_class_tensor = torch.tensor([target_class]).cuda()\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    current_iden_dir = os.path.join(attack_imgs_dir, \"iden_{}\".format(target_class))\n",
    "    _, initial_loss = decision(G(current_point.unsqueeze(0)), target_model, score=True,\n",
    "                               criterion=criterion, target=target_class_tensor)\n",
    "\n",
    "attack_single_target(current_point, target_class, initial_loss, G,\n",
    "                     target_model, E, attack_params, criterion,\n",
    "                     current_iden_dir)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: current number of distinct labels 202\n",
      "iter 1: current number of distinct labels 300\n"
     ]
    }
   ],
   "source": [
    "#current_point 是（有100个元素的tenosr）\n",
    "def gen_points_on_sphere(current_point, points_count, sphere_radius):\n",
    "    # get random perturbations\n",
    "    #points_shape is (32*100)\n",
    "    points_shape = (points_count,) + current_point.shape\n",
    "    #perturbation_direction is (32*100)\n",
    "    perturbation_direction = torch.randn(*points_shape).cuda()\n",
    "    dims = tuple([i for i in range(1, len(points_shape))])\n",
    "\n",
    "    # normalize them such that they are uniformly distributed on a sphere with the given radius\n",
    "    perturbation_direction = (sphere_radius / torch.sqrt(\n",
    "        torch.sum(perturbation_direction ** 2, axis=dims, keepdims=True))) * perturbation_direction\n",
    "\n",
    "    # add the perturbations to the current point\n",
    "    sphere_points = current_point + perturbation_direction\n",
    "    return sphere_points, perturbation_direction\n",
    "\n",
    "\n",
    "points = gen_initial_points_untargeted(attack_params['num_targets'],\n",
    "                                       attack_params['batch_dim_for_initial_points'],\n",
    "                                       G,\n",
    "                                       target_model,\n",
    "                                       attack_params['point_clamp_min'],\n",
    "                                       attack_params['point_clamp_max'],\n",
    "                                       attack_params['z_dim'])\n",
    "for target in points:\n",
    "    current_point = points[target].cuda()\n",
    "    new_points, perturbation_directions = gen_points_on_sphere(current_point,\n",
    "                                                               attack_params['sphere_points_count'],\n",
    "                                                               2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 15>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     13\u001B[0m             result[i] \u001B[38;5;241m=\u001B[39m result[i] \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result[::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m---> 15\u001B[0m \u001B[43msimple_multi\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m40\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36msimple_multi\u001B[1;34m(stra, strb)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msimple_multi\u001B[39m(stra, strb):\n\u001B[1;32m----> 2\u001B[0m     aa \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstra\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     bb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(strb)\n\u001B[0;32m      4\u001B[0m     lena \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(stra)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "def simple_multi(stra, strb):\n",
    "    aa = list(stra)\n",
    "    bb = list(strb)\n",
    "    lena = len(stra)\n",
    "    lenb = len(strb)\n",
    "    result = [0 for i in range(lena+lenb)]\n",
    "    for i in range(lena):\n",
    "        for j in range(lenb):\n",
    "            result[lena-i-1+lenb-j-1] += int(aa[i])*int(bb[j])\n",
    "    for i in range(len(result)-1):\n",
    "        if result[i] >= 10:\n",
    "            result[i+1] += result[i]//10\n",
    "            result[i] = result[i] % 10\n",
    "    return result[::-1]\n",
    "simple_multi(10,40)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
