{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3e6dbda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data length: 100000 \n",
      " user number: 943 \n",
      " item number: 1682\n",
      "train length: 80000 \n",
      " test length: 20000\n",
      "(943, 1682)\n",
      "epoch 1, train mae 0.725925, train rmse 0.852013\n",
      "epoch 2, train mae 0.524327, train rmse 0.724104\n",
      "epoch 3, train mae 0.513667, train rmse 0.716706\n",
      "epoch 4, train mae 0.521281, train rmse 0.721998\n",
      "epoch 5, train mae 0.536829, train rmse 0.732686\n",
      "epoch 6, train mae 0.527519, train rmse 0.726305\n",
      "epoch 7, train mae 0.511039, train rmse 0.714870\n",
      "epoch 8, train mae 0.492299, train rmse 0.701640\n",
      "epoch 9, train mae 0.491708, train rmse 0.701219\n",
      "epoch 10, train mae 0.494730, train rmse 0.703371\n",
      "epoch 11, train mae 0.488816, train rmse 0.699154\n",
      "epoch 12, train mae 0.480723, train rmse 0.693342\n",
      "epoch 13, train mae 0.481666, train rmse 0.694021\n",
      "epoch 14, train mae 0.481765, train rmse 0.694093\n",
      "epoch 15, train mae 0.477916, train rmse 0.691315\n",
      "epoch 16, train mae 0.475588, train rmse 0.689629\n",
      "epoch 17, train mae 0.473118, train rmse 0.687836\n",
      "epoch 18, train mae 0.471778, train rmse 0.686861\n",
      "epoch 19, train mae 0.473994, train rmse 0.688472\n",
      "epoch 20, train mae 0.472318, train rmse 0.687254\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data import *\n",
    "from evaluation import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "data_dir = 'datasets/ml-100k/ub.base'\n",
    "N, M, data_list, _ = load_data(file_dir=data_dir)\n",
    "print(' data length: %d \\n user number: %d \\n item number: %d' %(len(data_list),N,M))\n",
    "\n",
    "#\n",
    "# ### 分割数据集\n",
    "#\n",
    "#\n",
    "train_list, test_list = train_test_split(data_list,test_size=0.2)\n",
    "print ('train length: %d \\n test length: %d' %(len(train_list),len(test_list)))\n",
    "#\n",
    "# ### 将 list 转换成 矩阵\n",
    "train_mat = sequence2mat(sequence = train_list, N = N, M = M)\n",
    "test_mat = sequence2mat(sequence = test_list, N = N, M = M)\n",
    "print(train_mat.shape)\n",
    "\n",
    "# 定义网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,\n",
    "                 users_num=None,  # 用户数\n",
    "                 items_num=None,  # 商品数\n",
    "                 embedding_size=100,  # 嵌入空间维度\n",
    "                 hidden_sizes=[16, 8],  # 隐层节点数目\n",
    "                 learning_rate=0.005,  # 学习率\n",
    "                 lamda_regularizer=0.1,  # 正则项系数\n",
    "                 batch_size=256  # batch大小\n",
    "                 ):\n",
    "        super(Net, self).__init__()\n",
    "        self.users_num = users_num\n",
    "        self.items_num = items_num\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lamda_regularizer = lamda_regularizer\n",
    "        self.batch_size = batch_size\n",
    "        self.user_embedding=nn.Embedding(users_num,embedding_size)\n",
    "        self.item_embedding=nn.Embedding(items_num,embedding_size)\n",
    "        self.fc1 =nn.Linear(embedding_size*2, 64)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.fc2=nn.Linear(in_features=64,out_features=16,bias=True)\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.prediction_layer=nn.Linear(in_features=16,out_features=1,bias=True)\n",
    "    def forward(self, users_input,items_input):\n",
    "        embed_users=self.user_embedding(users_input)\n",
    "        embed_items=self.item_embedding(items_input)\n",
    "        x=torch.concat([embed_items,embed_users],1)\n",
    "        x=self.fc1(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.relu2(x)\n",
    "        x=self.prediction_layer(x)\n",
    "\n",
    "        return x\n",
    "class PMFDATASET(Dataset):\n",
    "    def __init__(self, u_id, i_id, rating):\n",
    "        self.u_id = u_id\n",
    "        self.i_id = i_id\n",
    "        self.rating = rating\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.u_id[index], self.i_id[index], self.rating[index]\n",
    "    def __len__(self):\n",
    "        return len(self.rating)\n",
    "\n",
    "def training(model, trainData,predData, batch_size,num_epochs=20, learning_rate=0.005):\n",
    "    train_dataset=PMFDATASET(trainData[:,0],trainData[:,1],predData)\n",
    "    train_loader=DataLoader(train_dataset,batch_size=batch_size)\n",
    "    #使用定义优化器\n",
    "    optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n",
    "    #定义损失函数 交叉熵代价函数\n",
    "    mess_loss=nn.MSELoss()\n",
    "    train_ls, valid_ls = [], []\n",
    "    rmse=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, total_len = 0.0, 0\n",
    "        total_loss2=0.0\n",
    "        for user_id,item_id,rating in train_loader:\n",
    "            #rating = rating.to(torch.int64)\n",
    "            y_pred=model(user_id,item_id)\n",
    "            l=mess_loss(y_pred,rating)\n",
    "            optimizer.zero_grad()  #梯度清零\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            total_loss+=l.item()\n",
    "            total_loss2+=l.item()\n",
    "            total_len+=len(y_pred)\n",
    "\n",
    "        train_ls.append(100*total_loss/total_len)\n",
    "        rmse.append(math.sqrt(100*total_loss2/total_len))\n",
    "        print('epoch %d, train mae %f, train rmse %f' % (epoch + 1, train_ls[-1],rmse[-1]))\n",
    "    return train_ls\n",
    "if __name__ == '__main__':\n",
    "    data=pd.read_table(\"datasets/ml-100k/ub.base\",engine='python',\n",
    "                       names=['uid', 'iid', 'score','timestramp'])\n",
    "\n",
    "    trianing_data=data.iloc[:,:2]\n",
    "    pred_data=data.iloc[:,2]\n",
    "    #转换为tensor\n",
    "    trianing_data=torch.tensor(trianing_data.values,dtype=torch.int64)\n",
    "    pred_data=torch.tensor(pred_data.values,dtype=torch.float32)\n",
    "    model=Net(  users_num=N*2,  # 用户数\n",
    "                 items_num=M*2)# 商品数)\n",
    "    training(model=model,trainData=trianing_data,predData=pred_data,batch_size=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b88e019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
